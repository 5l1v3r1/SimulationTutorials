{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Single neuron modelling tutorial\n",
    "\n",
    "____________\n",
    "\n",
    "In this tutorial we will see how to use experimental data from the Allen Institute for Brain Science Cell Types database and open-source software developed at the Blue Brain Project to constrain parameters of a multicompartmental neuron model with active dendrites.\n",
    "____________\n",
    "\n",
    "\n",
    "Authors of this script:\n",
    "\n",
    "Elisabetta Iavarone @ Blue Brain Project  \n",
    "Werner Van Geit @ Blue Brain Project  \n",
    "Christian RÃ¶ssert @ Blue Brain Project\n",
    "___\n",
    "### Overview:\n",
    "\n",
    "* We will use electrophysiological traces and a morphology of a [Layer 5 cortical interneuron from the visual cortex](http://celltypes.brain-map.org/mouse/experiment/electrophysiology/475049291?mode-toggle.x=50&mode-toggle.y=55). The choice of the fixed parameters is taken from the corresponding \"Biophysical - all active\" model.\n",
    "\n",
    "\n",
    "* Electrophysiological features will be extracted from the traces, thanks to the ** Electrophys Feature Extraction Library ** [eFEL](https://github.com/BlueBrain/eFEL).\n",
    "\n",
    "\n",
    "* We will use the **Blue Brain Python Optimisation Library** [BluePyOpt](https://github.com/BlueBrain/BluePyOpt) to create a model template for the [NEURON simulator](https://www.neuron.yale.edu/neuron/) and to constrain the model parameters.\n",
    "____\n",
    "\n",
    "Most examples in this demo can be run from a web browser, thanks to Binder (http://mybinder.org/, supported by The Freeman Lab @ HHMI Janelia Research Campus).\n",
    "\n",
    "To access the Binder instance set up for this demo, go [here](http://mybinder.org/repo/BlueBrain/SimulationTutorials/FENS2016).  \n",
    "\n",
    "You can run this tutorial on your computer, provided that you have NEURON/Python installed. The other libraries can be easily install using pip (see next section).\n",
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Uncomment these lines if you want to install the required software on your computer.\n",
    "# !pip install --user bluepyopt\n",
    "# !pip install --user allensdk\n",
    "# !pip install --user neurom"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first import some useful Python modules, the Allen SDK and API and the other libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload\n",
    "\n",
    "from allensdk.api.queries.biophysical_api import BiophysicalApi\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib notebook\n",
    "import collections\n",
    "\n",
    "import bluepyopt as bpopt\n",
    "import bluepyopt.ephys as ephys\n",
    "\n",
    "import numpy\n",
    "import json\n",
    "\n",
    "!nrnivmodl modfiles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Experimental data\n",
    "In this section we will process the electrophysiological data of a [Layer 5 cortical interneuron from the visual cortex](http://celltypes.brain-map.org/mouse/experiment/electrophysiology/475049291?mode-toggle.x=50&mode-toggle.y=55) and load the morphology .swc file.\n",
    "\n",
    "For this example we have chosen to use one negative current steps, one positive and we assign a name to them; each step is associated with a sweep number. The data are stored in a Python dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Load the .nwb file containing the voltage traces\n",
    "from allensdk.core.nwb_data_set import NwbDataSet\n",
    "nwb_data = NwbDataSet('data/475049288.nwb')\n",
    "\n",
    "# Store data in a dictionary step_name : sweep_num\n",
    "steps_dict = collections.OrderedDict(sorted({'StepNeg':23,'StepPos':36}.items(), key = lambda x:x[0]))\n",
    "\n",
    "def get_data(dataset,sweeps_dict):\n",
    "    # Correct for the liquid junction potential\n",
    "    junction_potential = -14\n",
    "    data = collections.OrderedDict()\n",
    "    for step, sweep in sweeps_dict.items():\n",
    "        sweep_data = {}\n",
    "        # Get sweep from NWB dataset\n",
    "        sweep = dataset.get_sweep(sweep)\n",
    "\n",
    "        # Get stimulus from the sweep\n",
    "        # stimulus = sweep['stimulus']\n",
    "\n",
    "        # Sampling rate is in Hz\n",
    "        sampling_rate = sweep['sampling_rate']\n",
    "        \n",
    "        # Start/stop indices that exclude the experimental test pulse (if applicable)\n",
    "        index_range = sweep['index_range']\n",
    "        \n",
    "        # Response is a numpy array in mV\n",
    "        sweep_data['V'] = sweep['response'][index_range[0]:index_range[1]]*1000+junction_potential    \n",
    "        \n",
    "        # Define some time points in milliseconds (i.e., convert to absolute time)\n",
    "        sweep_data['T'] = numpy.arange(0,(len(sweep_data['V'])/sampling_rate),1./sampling_rate)*1000\n",
    "        data[step] = sweep_data\n",
    "    return data\n",
    "\n",
    "data_dict = get_data(nwb_data, steps_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the morphology file and display with the library [**NeuroM**](https://github.com/BlueBrain/NeuroM) developed at BBP."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Import NeuroM and display the morphology\n",
    "from neurom import viewer, fst\n",
    "\n",
    "morphology_file = 'Sst-IRES-Cre_Ai14_IVSCC_-183332.05.02.01_486041253_m.swc'\n",
    "nrn = fst.load_neuron(morphology_file)\n",
    "viewer.draw(nrn, mode='3d')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Electrophysiological features\n",
    "To build a detailed neuron model, we need to quantify the electrical behavior we want to reproduce. The metrics we use are the eFeatures, that measure parameters describing for instance the shape of the action potential or the firing properties of a neuron (for examples, see [here](http://bluebrain.github.io/eFEL/eFeatures.html)).\n",
    "\n",
    "In this particular example, we extract distinct features from the responses to the negative and positive voltage steps.\n",
    "The eFeatures extracted from the data and later from the model will be used to evaluate the results of the simulations. The features values, along with the standard deviations are stored in a .json file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Extract features\n",
    "import efel\n",
    "def get_features(data):\n",
    "    \n",
    "    traces_pas = []\n",
    "    traces_act = []\n",
    "    for step_name, step_traces in data.items():\n",
    "        trace = {}\n",
    "        trace['T'] = data[step_name]['T']\n",
    "        trace['V'] = data[step_name]['V']\n",
    "        trace['stim_start'] = [270]\n",
    "        trace['stim_end'] = [1270]\n",
    "        trace['name'] = step_name\n",
    "    \n",
    "        if 'Pos' in step_name:\n",
    "            traces_act.append(trace)       \n",
    "        else:\n",
    "            traces_pas.append(trace)\n",
    "            \n",
    "    features_values = efel.getMeanFeatureValues(traces_pas, ['time_constant', 'voltage_base',\n",
    "                                                                    'voltage_deflection_begin', 'steady_state_hyper'])\n",
    "    features_values_act = efel.getMeanFeatureValues(traces_act, ['mean_frequency', 'adaptation_index2', 'ISI_CV', \n",
    "                                                                'doublet_ISI', 'time_to_first_spike', \n",
    "                                                                'AHP_slow_time', 'AP_width', 'AP_height', 'Spikecount']) \n",
    "    features_values.extend(features_values_act)\n",
    "    return features_values\n",
    "\n",
    "efel_features = get_features(data_dict)\n",
    "\n",
    "# Write features mean values and std in a json file\n",
    "features_dict = collections.OrderedDict()\n",
    "for step_name, features in zip(steps_dict.iterkeys(), efel_features):\n",
    "    features_dict[step_name] = {\"soma\":{}}\n",
    "    for name, value in features.items():\n",
    "        features_dict[step_name][\"soma\"][name] = [value, abs(value*0.05)]    \n",
    "    \n",
    "with open('./config/features.json', 'w') as fp:\n",
    "    json.dump(features_dict, fp, indent = 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Model definition\n",
    "In this section we will define the neuron model template and the parameters that we will optimize later on. The fixed parameters are taken from the \"Biophysical - All active\" model from the ABI models database. To download the original model and data uncomment the following lines (before you would need to create a folder called \"neuronal model\")."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Download the cell model\n",
    "\n",
    "# bp = BiophysicalApi()\n",
    "# neuronal_model_id = 501349536\n",
    "# bp.cache_data(neuronal_model_id, working_directory='neuronal_model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following steps we will use some BluePyOpt functionalities to set-up the model template and optimize the free parameters. First of all, we use the \"ephys\" module to load the morphology. The axon is replaces by a model of the axonal initial segment (AIS)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "morphology = ephys.morphologies.NrnFileMorphology(morphology_file, do_replace_axon=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ion channel parameters and distribution in the different compartments (soma, basal dendrite, AIS) are stored in a .json file (in \"config/parameters.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Parameters\n",
    "param_configs = json.load(open('config/parameters.json'))\n",
    "print [param_config['param_name'] for param_config in param_configs]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The file \"cell_model.py\" contains some helper functions for automatic creation of the model template. In this case we are loading the parameters we defined in the .json file. Note that some parameters have fixed values (they are \"frozen\" parameters), while others are defined as a range (\"free\" parameters)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Insert parameters in the cell model\n",
    "import cell_model\n",
    "parameters = cell_model.define_parameters()\n",
    "print '\\n'.join('%s' % param for param in parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The parameters we defined above describe the maximal conductances of the ion channels and the kinetics parameters of the intracellular calcium dynamics. With the following function call, the .mod files that define the ion channel models are inserted in the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Define mechanisms\n",
    "mechanisms = cell_model.define_mechanisms()\n",
    "print '\\n'.join('%s' % mech for mech in mechanisms)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are ready to create the cell model, with a simple call to the class \"CellModel\" of the \"ephys\" module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create the cell model\n",
    "abi_cell = ephys.models.CellModel('abi_cell', morph=morphology, mechs=mechanisms, params=parameters)\n",
    "print abi_cell"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the next step we will fit the maximal conductance of some of the ion channels in order to reproduce the eFeatures we have extracted from the data. In the following line we can see which are the \"free\" parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Parameters to optimize\n",
    "param_names = [param.name for param in abi_cell.params.values() if not param.frozen]\n",
    "print param_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Setting-up a simulation\n",
    "To evaluate the behavior of the model, we need to set-up a simulation. To reproduce the experimental sweeps we have chosen, we define two current protocols that match the experimental counterparts. The protocols information is also stored in a .json file and can be automaically loaded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import cell_evaluator\n",
    "proto_configs = json.load(open('config/protocols.json'))\n",
    "fitness_protocols = cell_evaluator.define_protocols()\n",
    "\n",
    "print proto_configs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thanks to another helper class of the BluePyOpt library it is easy to define a simulation. The additional file \"cell_evaluator.py\" can be used to set up the simulation and define a scoring system that will be used by the genetic algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Set-up a simulation and a fitness calculator\n",
    "sim = ephys.simulators.NrnSimulator()\n",
    "fitness_calculator = cell_evaluator.define_fitness_calculator(fitness_protocols)\n",
    "\n",
    "evaluator = ephys.evaluators.CellEvaluator(                                          \n",
    "        cell_model=abi_cell,                                                       \n",
    "        param_names=param_names,                                                    \n",
    "        fitness_protocols=fitness_protocols,                                        \n",
    "        fitness_calculator=fitness_calculator,                                      \n",
    "        sim=sim)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The result of the simulations can be visualized in the different ways. For example, the following function plots the experimental and model responses one on top of the other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def plot_data(sweep_data, sweeps_list, model_responses = []):\n",
    "    fig, axes = plt.subplots(len(sweeps_list), figsize=(10,10))\n",
    "    \n",
    "    for index, sweep, (resp_name, model) in zip(range(len(sweeps_list)),sweeps_list, sorted(model_responses.items())):\n",
    "        sweep = sweep_data.get_sweep(sweep)\n",
    "\n",
    "        # Get stimulus from the sweep\n",
    "        stimulus = sweep['stimulus']\n",
    "\n",
    "        # Sampling rate is in Hz\n",
    "        sampling_rate = sweep['sampling_rate']\n",
    "        \n",
    "        # Start/stop indices that exclude the experimental test pulse (if applicable)\n",
    "        index_range = sweep['index_range']\n",
    "        \n",
    "        # Response is a numpy array in Volts\n",
    "        response = sweep['response'][index_range[0]:index_range[1]]*1000    \n",
    "        \n",
    "        # Define some time points in seconds (i.e., convert to absolute time)\n",
    "        time_pts = numpy.arange(0,(len(response)/sampling_rate),1./sampling_rate)\n",
    "        \n",
    "        axes[index].plot(time_pts, response-14, label = 'Data')\n",
    "        axes[index].plot(model['time']/1000, model['voltage'], label = 'Model')\n",
    "       \n",
    "        axes[index].set_xlim([0.0, 1.54])\n",
    "        axes[index].set_xlabel(\"Time (s)\")\n",
    "        axes[index].set_ylabel(\"Voltage (mV)\")\n",
    "        #axes[index].set_title(resp_name)\n",
    "        axes[index].legend(loc='best')\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the following function call we run a simulation with parameters from the original ABI model. We can also print the scores of the original model. This score measures the difference of each eFeature of the model from the experimental one and penalize the eFeatures that display the wider experimental variability (in our case all the features have the same STD). A \"perfect\" model would have a score close to 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "orig_params = json.load(open('orig_parameters.json'))\n",
    "abi_cell.unfreeze(abi_cell.params)\n",
    "orig_responses = evaluator.run_protocols(protocols=fitness_protocols.values(), param_values = orig_params)\n",
    "plot_data(nwb_data,[23, 36], orig_responses)\n",
    "\n",
    "scores =  fitness_calculator.calculate_scores(orig_responses)\n",
    "sum = numpy.sum([value for value in scores.values()])\n",
    "avg = numpy.mean([value for value in scores.values()])\n",
    "\n",
    "print \"Sum of all feature values: \" + str(sum)\n",
    "print \"Average of the feature values: \" + str(avg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Parameters optimization \n",
    "We are now ready to run an optimisation. This is a procedure that requires supercomputing resources and can take from some hours to days. AS a proof of concept, we will run two optimization with a small population of individual for a small number of generations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import time\n",
    "# Run for 2 generations\n",
    "import pickle\n",
    "\n",
    "# Re-initialize the model parameters\n",
    "param_configs = json.load(open('config/parameters.json'))\n",
    "parameters = cell_model.define_parameters()\n",
    "abi_cell = ephys.models.CellModel('abi_cell', morph=morphology, mechs=mechanisms, params=parameters)\n",
    "\n",
    "evaluator = ephys.evaluators.CellEvaluator(                                          \n",
    "        cell_model=abi_cell,                                                       \n",
    "        param_names=param_names,                                                    \n",
    "        fitness_protocols=fitness_protocols,                                        \n",
    "        fitness_calculator=fitness_calculator,                                      \n",
    "        sim=sim)  \n",
    "\n",
    "num_gen = 2\n",
    "opt = bpopt.optimisations.DEAPOptimisation(                                     \n",
    "    evaluator=evaluator,                                                            \n",
    "    offspring_size=10) \n",
    "\n",
    "start = time.time()\n",
    "results = opt.run(max_ngen=num_gen, cp_filename='checkpoints/checkpoint_'+str(num_gen)+'.pkl')\n",
    "end = time.time()\n",
    "print \"Run time in seconds: \" + str(end-start)\n",
    "\n",
    "cp = pickle.load(open('checkpoints/checkpoint_'+str(num_gen)+'.pkl'))\n",
    "results = (cp['population'],\n",
    "        cp['halloffame'],\n",
    "        cp['logbook'],\n",
    "        cp['history'])\n",
    "\n",
    "\n",
    "pop, hall_of_fame_2, log, hist = results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After two generations, the model result is not very satisfying."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Plot responses of the best individual\n",
    "best_params_2 = evaluator.param_dict(hall_of_fame_2[0])\n",
    "best_responses_2 = evaluator.run_protocols(protocols=fitness_protocols.values(), param_values=best_params_2)\n",
    "\n",
    "plot_data(nwb_data,[23, 36],best_responses_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We run a slightly longer optimization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Run for 8 generations\n",
    "import time\n",
    "\n",
    "num_gen = 8\n",
    "opt = bpopt.optimisations.DEAPOptimisation(                                     \n",
    "    evaluator=evaluator,                                                            \n",
    "    offspring_size=10) \n",
    "\n",
    "start = time.time()\n",
    "results = opt.run(max_ngen=num_gen, cp_filename='checkpoints/checkpoint_'+str(num_gen)+'.pkl')\n",
    "#final_pop, halloffame, log, hist = opt.run(max_ngen=2, cp_filename='checkpoints/checkpoint.pkl')\n",
    "end = time.time()\n",
    "print \"Run time in seconds: \" + str(end-start)\n",
    "\n",
    "cp = pickle.load(open('checkpoints/checkpoint_'+str(num_gen)+'.pkl'))\n",
    "results = (cp['population'],\n",
    "        cp['halloffame'],\n",
    "        cp['logbook'],\n",
    "        cp['history'])\n",
    "\n",
    "pop, hall_of_fame, log, hist = results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also plot the evolution of the feature values from generation to generation. Although the result is not yet satisfying, we can observe a progressive convergence of the model features values toward the experimental ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gen_numbers = log.select('gen')\n",
    "min_fitness = numpy.array(log.select('min'))\n",
    "max_fitness = log.select('max')\n",
    "mean_fitness = numpy.array(log.select('avg'))\n",
    "std_fitness = numpy.array(log.select('std'))\n",
    "\n",
    "fig, ax = plt.subplots(1, figsize=(8, 8), facecolor='white')\n",
    "#fig_trip, ax_trip = plt.subplots(1, figsize=(10, 5), facecolor='white')\n",
    "\n",
    "#plot_count = len(responses)\n",
    "std = std_fitness\n",
    "mean = mean_fitness\n",
    "minimum = min_fitness\n",
    "stdminus = mean - std                                                           \n",
    "stdplus = mean + std\n",
    "\n",
    "ax.plot(                                                                      \n",
    "    gen_numbers,                                                                \n",
    "    mean,                                                                       \n",
    "    color='black',                                                              \n",
    "    linewidth=2,                                                                \n",
    "    label='population average')                                                 \n",
    "\n",
    "ax.fill_between(                                                              \n",
    "    gen_numbers,                                                                \n",
    "    stdminus,                                                                   \n",
    "    stdplus,                                                                    \n",
    "    color='lightgray',                                                          \n",
    "    linewidth=2,                                                                \n",
    "    label=r'population standard deviation')                                     \n",
    "\n",
    "ax.plot(                                                                      \n",
    "    gen_numbers,                                                                \n",
    "    minimum,                                                                    \n",
    "    color='red',                                                                \n",
    "    linewidth=2,                                                                \n",
    "    label='population minimum')                                                 \n",
    "\n",
    "ax.set_xlim(min(gen_numbers) - 1, max(gen_numbers) + 1)                       \n",
    "ax.set_xlabel('Generation #')                                                 \n",
    "ax.set_ylabel('Sum of objectives')                                            \n",
    "ax.set_ylim([0, max(stdplus)])                                                \n",
    "ax.legend()          "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plotting the voltage responses shows that the result can still be improved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Plot responses of the best individual\n",
    "best_params_8 = evaluator.param_dict(hall_of_fame[0])\n",
    "best_responses_8 = evaluator.run_protocols(protocols=fitness_protocols.values(), param_values=best_params_8)\n",
    "\n",
    "plot_data(nwb_data,[23, 36],best_responses_8)\n",
    "print log"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
